---
layout: subpage
title: Fairness in Recommendation System
description: Regularization and Constrained Optimization (In-Processing)
---

<!-- - [<font color="DarkOrchid">' </font>\|<font color="DarkSalmon"> </font>]() \| <font color="Violet">[ Fairness +  Fairness]</font> \| [<font color="DeepPink">知乎</font>]() -->
- [<font color="DarkOrchid">23'AAAI </font>\|<font color="DarkSalmon"> Fair Representation Learning for Recommendation A Mutual Information Perspective </font>](https://le-wu.com/files/Publications/CONFERENCES/AAAI23.pdf) \| <font color="Violet">[Group Fairness + User Fairness]</font>
- [<font color="DarkOrchid">TOIS'22 </font>\|<font color="DarkSalmon"> A Multi-objective Optimization Framework for Multi-stakeholder Fairness-aware Recommendation</font>](chrome-extension://ikhdkkncnoglghljlkmcimlnlhkeamad/pdf-viewer/web/viewer.html?file=https%3A%2F%2Farxiv.org%2Fpdf%2F2105.02951.pdf) \| <font color="Violet">[Group Fairness + User Fairness + Producer Fairness]</font> \| [<font color="DeepPink">知乎</font>](https://zhuanlan.zhihu.com/p/589152042)
- [<font color="DarkOrchid">EMNLP'22 </font>\|<font color="DarkSalmon"> MABEL Attenuating Gender Bias using Textual Entailment Data</font>](https://arxiv.org/abs/2210.14975) \| <font color="Violet">[Group Fairness + User Fairness]</font> \| [<font color="DeepPink">知乎</font>](https://zhuanlan.zhihu.com/p/591626090)
- [<font color="DarkOrchid">WWW'21 </font>\|<font color="DarkSalmon"> Debiasing Career Recommendations with Neural Fair Collaborative Filtering</font>](https://dl.acm.org/doi/10.1145/3442381.3449904) \| <font color="Violet">[Group Fairness + User Fairness]</font> \| [<font color="DeepPink">知乎</font>](https://zhuanlan.zhihu.com/p/467696782)
- [<font color="DarkOrchid">WSDM'21 </font>\|<font color="DarkSalmon"> Practical Compositional Fairness: Understanding Fairness in Multi-Component Recommender Systems</font>](https://dl.acm.org/doi/abs/10.1145/3437963.3441732) \| <font color="Violet">[Group Fairness + User Fairness]</font> \| [<font color="DeepPink">知乎</font>](https://zhuanlan.zhihu.com/p/478404948)
- [<font color="DarkOrchid">WSDM'20 </font>\|<font color="DarkSalmon"> Addressing Marketing Bias in Product Recommendations</font>](https://dl.acm.org/doi/abs/10.1145/3336191.3371855) \| <font color="Violet">[Group Fairness + User Fairness + Item Fairness]</font> \| [<font color="DeepPink">知乎</font>](https://zhuanlan.zhihu.com/p/608319035)
- [<font color="DarkOrchid">KDD'19 </font>\|<font color="DarkSalmon"> Fairness in Recommendation Ranking through Pairwise Comparisons</font>](https://dl.acm.org/doi/abs/10.1145/3292500.3330745) \| <font color="Violet">[Group Fairness + Item Fairness]</font> \| [<font color="DeepPink">知乎</font>](https://zhuanlan.zhihu.com/p/472696909)
- [<font color="DarkOrchid">CIKM'18 </font>\|<font color="DarkSalmon"> Fairness-Aware Tensor-Based Recommendation</font>](https://dl.acm.org/doi/10.1145/3269206.3271795) \| <font color="Violet">[Group Fairness + User Fairness]</font> \| [<font color="DeepPink">知乎</font>](https://zhuanlan.zhihu.com/p/468267697)
- [<font color="DarkOrchid">FAT'18 </font>\|<font color="DarkSalmon"> Recommendation Independence</font>](http://proceedings.mlr.press/v81/kamishima18a.html) \| <font color="Violet">[Group Fairness + User Fairness + Item Fairness]</font>
- [<font color="DarkOrchid">FAT'18 </font>\|<font color="DarkSalmon"> Balanced Neighborhoods for Multi-sided Fairness in Recommendation</font>](https://proceedings.mlr.press/v81/burke18a.html) \| <font color="Violet">[Group Fairness + User Fairness + Item Fairness]</font>
- [<font color="DarkOrchid">NIPS'17 </font>\|<font color="DarkSalmon"> Beyond Parity: Fairness Objectives for Collaborative Filtering</font>](https://proceedings.neurips.cc/paper/2017/hash/e6384711491713d29bc63fc5eeb5ba4f-Abstract.html) \| <font color="Violet">[Group Fairness + User Fairness]</font> \| [<font color="DeepPink">知乎</font>](https://zhuanlan.zhihu.com/p/436851842)

# Others
- [<font color="DarkOrchid">KDD'21 </font>\|<font color="DarkSalmon"> Understanding and Improving Fairness-Accuracy Trade-offs in Multi-Task Learning</font>](https://dl.acm.org/doi/10.1145/3447548.3467326) \| <font color="Violet">[Group Fairness + User Fairness]</font> \| [<font color="DeepPink">知乎</font>](https://zhuanlan.zhihu.com/p/560653562)

